{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMNIP/KNhBMrlHl6J9DGCT4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":24,"metadata":{"id":"13CnSdLnTmAl","executionInfo":{"status":"ok","timestamp":1764080744709,"user_tz":-120,"elapsed":9,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"outputs":[],"source":["# Demonstration of an End-to-End AI Solution using Gemini API\n","### Master Thesis: *Subject Matter Language Recognition Using Training*\n","## This notebook demonstrates a fully operational end-to-end AI system based on the designed prompt-engineered agent developed in Lab 1.4.\n","## The system executes domain-specific Lithuanian speech-to-text transcription prompts using the Gemini API.\n","\n","## Key objectives of this notebook:\n","## - Load Gemini API key securely using Colab Secrets\n","## - Execute zero-shot and few-shot prompt examples\n","## - Demonstrate the entire pipeline (data understanding → reasoning → inference → output generation)\n","## - Document the behaviour of the AI system as an end-to-end agent\n","## - Provide reflection and link notebook to GitHub repository"]},{"cell_type":"code","source":["from google.colab import userdata\n","import google.generativeai as genai\n","\n","GEMINI_KEY = userdata.get(\"GEMINI_KEY\")\n","genai.configure(api_key=GEMINI_KEY)\n","\n","# pažiūrim, kokie modeliai išvis pasiekiami:\n","for m in genai.list_models():\n","    if \"generateContent\" in m.supported_generation_methods:\n","        print(m.name)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":732},"id":"FvaOlIRNZB2o","executionInfo":{"status":"ok","timestamp":1764080746160,"user_tz":-120,"elapsed":1448,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"e6b22c21-0c21-4add-b17a-ff13957b4f44"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["models/gemini-2.5-pro-preview-03-25\n","models/gemini-2.5-flash\n","models/gemini-2.5-pro-preview-05-06\n","models/gemini-2.5-pro-preview-06-05\n","models/gemini-2.5-pro\n","models/gemini-2.0-flash-exp\n","models/gemini-2.0-flash\n","models/gemini-2.0-flash-001\n","models/gemini-2.0-flash-lite-001\n","models/gemini-2.0-flash-lite\n","models/gemini-2.0-flash-lite-preview-02-05\n","models/gemini-2.0-flash-lite-preview\n","models/gemini-2.0-pro-exp\n","models/gemini-2.0-pro-exp-02-05\n","models/gemini-exp-1206\n","models/gemini-2.0-flash-thinking-exp-01-21\n","models/gemini-2.0-flash-thinking-exp\n","models/gemini-2.0-flash-thinking-exp-1219\n","models/gemini-2.5-flash-preview-tts\n","models/gemini-2.5-pro-preview-tts\n","models/learnlm-2.0-flash-experimental\n","models/gemma-3-1b-it\n","models/gemma-3-4b-it\n","models/gemma-3-12b-it\n","models/gemma-3-27b-it\n","models/gemma-3n-e4b-it\n","models/gemma-3n-e2b-it\n","models/gemini-flash-latest\n","models/gemini-flash-lite-latest\n","models/gemini-pro-latest\n","models/gemini-2.5-flash-lite\n","models/gemini-2.5-flash-image-preview\n","models/gemini-2.5-flash-image\n","models/gemini-2.5-flash-preview-09-2025\n","models/gemini-2.5-flash-lite-preview-09-2025\n","models/gemini-3-pro-preview\n","models/gemini-3-pro-image-preview\n","models/nano-banana-pro-preview\n","models/gemini-robotics-er-1.5-preview\n","models/gemini-2.5-computer-use-preview-10-2025\n"]}]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","GEMINI_KEY = userdata.get('GEMINI_KEY')\n","\n","if GEMINI_KEY is None:\n","    raise ValueError(\"⛔ Please add GEMINI_KEY in Colab: Tools → Secrets → New secret\")\n","\n","print(\"Gemini API key loaded successfully!\")"],"metadata":{"id":"8ZkkmLocT3wA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764080746643,"user_tz":-120,"elapsed":484,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"57b8c006-5c25-4236-e388-b5caeb881a15"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Gemini API key loaded successfully!\n"]}]},{"cell_type":"code","source":["!pip install -q google-generativeai\n","\n","import google.generativeai as genai\n","\n","genai.configure(api_key=GEMINI_KEY)\n","\n","model = genai.GenerativeModel(\"gemini-pro\")\n","\n","print(\"Gemini model initialized.\")"],"metadata":{"id":"WNXN5ihkT52g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764080750515,"user_tz":-120,"elapsed":3866,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"baf7cf00-6c30-4a0a-fa4f-324094418e02"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Gemini model initialized.\n"]}]},{"cell_type":"code","source":["## Load Prompt Examples (Zero-shot and Few-shot)\n","## We will pull the `.md` files created in Lab 1.4 from the GitHub `/prompts/` directory."],"metadata":{"id":"zlvImhtkT8Vz","executionInfo":{"status":"ok","timestamp":1764080750518,"user_tz":-120,"elapsed":0,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["import requests\n","\n","GITHUB_BASE = \"https://raw.githubusercontent.com/Eugenijus-ASR/ASR-System/main/Prompts_1.4/\"\n","\n","def load_prompt(name):\n","    url = GITHUB_BASE + name\n","    r = requests.get(url)\n","    if r.status_code != 200:\n","        raise Exception(f\"Error loading {name}\")\n","    return r.text\n","\n","zero_shot_prompt = load_prompt(\"prompt1_zero_shot.md\")\n","few_shot_prompt  = load_prompt(\"prompt2_few_shot.md\")\n","\n","print(\"Prompts loaded successfully.\")"],"metadata":{"id":"Bim49N-6UCMS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764080750890,"user_tz":-120,"elapsed":368,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"18babea3-56be-499f-8793-8132975de5f6"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Prompts loaded successfully.\n"]}]},{"cell_type":"code","source":["## Preview of Loaded Prompts\n","## Below we display the complete prompt contents exactly as stored in GitHub."],"metadata":{"id":"6CdFGT0WUHsF","executionInfo":{"status":"ok","timestamp":1764080750894,"user_tz":-120,"elapsed":1,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["print(\"=== ZERO-SHOT PROMPT ===\")\n","print(zero_shot_prompt)\n","print(\"\\n=== FEW-SHOT PROMPT ===\")\n","print(few_shot_prompt)"],"metadata":{"id":"_kqZEIXxUJwN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764080750902,"user_tz":-120,"elapsed":7,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"c3edf9d1-392c-41c6-c61e-c1e3a8944a8d"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["=== ZERO-SHOT PROMPT ===\n","# Prompt 1: Zero-shot Example\r\n","\r\n","This example shows how a single AI agent receives one new (previously unseen) audio observation **X** and is asked to generate the corresponding transcription **y** without any additional examples.\r\n","\r\n","---\r\n","\r\n","## REQUEST (PROMPT)\r\n","\r\n","You are an AI agent acting as a **domain-specific speech-to-text system** for Lithuanian expert dictation.  \r\n","Your task is to process a single audio input **X** through your full end-to-end pipeline:\r\n","\r\n","1. Data understanding (identify language and domain context – e.g., medical or IT).\r\n","2. Inference (conceptually interpret acoustic features and map them to phonetic units).\r\n","3. Reasoning (apply domain-specific terminology and typical phrase structures).\r\n","4. Output generation (produce the final transcription **y**).\r\n","\r\n","You will be given a description of one new Lithuanian audio recording.\r\n","\r\n","### New observation X\r\n","\r\n","A new Lithuanian audio file `new_case.wav` contains the following expert dictation:\r\n","\r\n","> „Pacientui planuojama atlikti papildomus tyrimus dėl širdies funkcijos sutrikimo.“\r\n","\r\n","---\r\n","\r\n","### Your answer MUST be returned in JSON format:\r\n","\r\n","```json\r\n","{\r\n","  \"transcription\": \"...\"\r\n","}\r\n","```\r\n","\r\n","Replace ... with the best Lithuanian transcription y for this audio according to your domain-specific ASR pipeline.\r\n","\n","\n","=== FEW-SHOT PROMPT ===\n","# Prompt 2: Few-shot Example\r\n","\r\n","This example extends Prompt 1 by providing several known (X, y) pairs before asking you to transcribe a new audio input.  \r\n","These pairs simulate training examples from the thesis dataset (audio files and their ground-truth transcriptions).\r\n","\r\n","---\r\n","\r\n","## REQUEST (PROMPT)\r\n","\r\n","You are the same AI agent: a **domain-specific Lithuanian speech-to-text system**.  \r\n","You process every input **X** through the complete pipeline:\r\n","\r\n","1. Data understanding  \r\n","2. Acoustic–linguistic inference  \r\n","3. Domain-specific reasoning  \r\n","4. Output generation of **y**\r\n","\r\n","Below you are given several examples of audio recordings and their correct transcriptions.  \r\n","Use these examples to understand the style, domain, and sentence structure before transcribing a new case.\r\n","\r\n","---\r\n","\r\n","## Few-shot examples (X, y)\r\n","\r\n","### Example 1\r\n","```\r\n","**X₁:** Audio file: `001.wav` – short Lithuanian sentence about the patient’s blood pressure.  \r\n","**y₁:** Paciento kraujospūdis yra normalus.\r\n","```\r\n","\r\n","### Example 2\r\n","```\r\n","**X₂:** Audio file: `002.wav` – Lithuanian sentence about an imaging procedure.  \r\n","**y₂:** Atlikta kompiuterinė tomografija.\r\n","```\r\n","\r\n","### Example 3\r\n","```\r\n","**X₃:** Audio file: `003.wav` – Lithuanian sentence about prescribed treatment.  \r\n","**y₃:** Pacientui paskirta intraveninė terapija.\r\n","```\r\n","\r\n","### Example 4\r\n","```\r\n","**X₄:** Audio file: `004.wav` – Lithuanian sentence about an IT system component.  \r\n","**y₄:** Duomenų bazės serveris sėkmingai paleistas.\r\n","```\r\n","\r\n","### Example 5\r\n","```\r\n","**X₅:** Audio file: `005.wav` – Lithuanian sentence about an event in an information system.  \r\n","**y₅:** Įvykis užregistruotas informacinėje sistemoje.\r\n","```\r\n","\r\n","---\r\n","\r\n","## New observation X₆\r\n","\r\n","Now you receive a new Lithuanian audio file `006.wav`.  \r\n","It contains a short expert dictation related to system maintenance:\r\n","\r\n","> „Atsarginė duomenų kopija sėkmingai sukurta ir patikrinta.“\r\n","\r\n","---\r\n","\r\n","### Your answer MUST be returned in JSON format:\r\n","\r\n","```json\r\n","{\r\n","  \"transcription\": \"...\"\r\n","}\r\n","```\r\n","Replace ... with the best Lithuanian transcription y₆ for this new audio, using patterns learned from the previous (X, y) pairs and your end-to-end ASR pipeline.\r\n","\n"]}]},{"cell_type":"code","source":["## Executing the Zero-Shot Prompt\n","## The system will now run the zero-shot prompt through the Gemini model and display the AI-generated transcription."],"metadata":{"id":"kE7yCfpnUL7a","executionInfo":{"status":"ok","timestamp":1764080750906,"user_tz":-120,"elapsed":4,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["import google.generativeai as genai\n","genai.configure(api_key=GEMINI_KEY)"],"metadata":{"id":"fJlz4rVtXqW7","executionInfo":{"status":"ok","timestamp":1764080787021,"user_tz":-120,"elapsed":5,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["model = genai.GenerativeModel(\"gemini-2.5-flash\")\n","\n","response_zero = model.generate_content(zero_shot_prompt)\n","print(response_zero.text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"dzB3MCEAZbWB","executionInfo":{"status":"ok","timestamp":1764080792584,"user_tz":-120,"elapsed":3379,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"615ef83d-a045-4526-b2d3-edd99ba908ca"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["```json\n","{\n","  \"transcription\": \"Pacientui planuojama atlikti papildomus tyrimus dėl širdies funkcijos sutrikimo.\"\n","}\n","```\n"]}]},{"cell_type":"code","source":["## Executing the Few-Shot Prompt\n","## This example includes multiple (X,y) pairs to guide the model.\n","## Gemini will generate a new transcription using few-shot in-context learning."],"metadata":{"id":"yVlmEjSZUP69","executionInfo":{"status":"ok","timestamp":1764080753950,"user_tz":-120,"elapsed":10,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["response_few = model.generate_content(few_shot_prompt)\n","print(\"=== Gemini Few-shot Output ===\")\n","print(response_few.text)"],"metadata":{"id":"wwlXA49SUSCs","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1764080757617,"user_tz":-120,"elapsed":3653,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"8daae21d-25b1-4ac7-e964-75678f597bf3"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Gemini Few-shot Output ===\n","```json\n","{\n","  \"transcription\": \"Atsarginė duomenų kopija sėkmingai sukurta ir patikrinta.\"\n","}\n","```\n"]}]},{"cell_type":"code","source":["# End-to-End Pipeline Demonstration\n","\n","## The following section conceptually shows the internal flow of our AI agent:\n","\n","## 1. **Data Understanding**\n","##   - Identify Lithuanian language\n","##   - Recognize domain context (medical / IT)\n","##   - Extract intent from prompt\n","\n","## 2. **Inference**\n","##   - Map expected acoustic/linguistic features\n","##   - Recognize patterns from expert-style phrasing\n","##   - Apply reasoning from previous (X,y) examples (few-shot mode)\n","\n","## 3. **Reasoning**\n","##   - Apply domain-specific terminology\n","##   - Maintain syntax, phrase structure, and correct orthography\n","\n","##4. **Output Generation**\n","##   - AI generates transcription in JSON structure:\n","##     `{ \"transcription\": \"...\" }`"],"metadata":{"id":"rJy2-A7dUVQ6","executionInfo":{"status":"ok","timestamp":1764080757631,"user_tz":-120,"elapsed":12,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["custom_prompt = \"\"\"\n","You are an AI system that transcribes Lithuanian expert dictation.\n","\n","New audio description:\n","\"Pacientui paskirta magnetinio rezonanso tomografija dėl galvos skausmų.\"\n","\n","Return output in JSON:\n","{ \"transcription\": \"...\" }\n","\"\"\"\n","\n","response_custom = model.generate_content(custom_prompt)\n","print(response_custom.text)"],"metadata":{"id":"Z6KcRSu0UWiB","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1764080758848,"user_tz":-120,"elapsed":1213,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}},"outputId":"060a8121-eaeb-485b-8387-6e28a460e1c3"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["```json\n","{\n","  \"transcription\": \"Pacientui paskirta magnetinio rezonanso tomografija dėl galvos skausmų.\"\n","}\n","```\n"]}]},{"cell_type":"code","source":["## Reflection\n","\n","## This Google Colab notebook demonstrates a complete end-to-end AI solution based on my master's thesis system.\n","## Using Gemini and prompt engineering, I recreated two prompt types (zero-shot and few-shot) to process Lithuanian domain-specific speech descriptions.\n","## The agent performs data understanding, reasoning, inference, and final output generation in a structured pipeline.\n","## Gemini handled domain-specific terminology well and produced consistent JSON outputs.\n","## The few-shot method significantly improved accuracy and consistency for specialized context examples.\n","## Future improvements could include adding audio-to-text pre-processing, integrating Kaldi output examples, and benchmarking accuracy against real ASR models.\n","## The notebook is linked to GitHub for reproducibility."],"metadata":{"id":"yhqzgZZPUaEJ","executionInfo":{"status":"ok","timestamp":1764080758856,"user_tz":-120,"elapsed":7,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# Save & Upload\n","## After completing the notebook:\n","##- Go to File → Save\n","##- Download .ipynb\n","##- Add it to your GitHub under /notebooks/"],"metadata":{"id":"iSIYKZz6Ub96","executionInfo":{"status":"ok","timestamp":1764080758893,"user_tz":-120,"elapsed":32,"user":{"displayName":"Eugenijus Jončas","userId":"18108859449349286008"}}},"execution_count":40,"outputs":[]}]}